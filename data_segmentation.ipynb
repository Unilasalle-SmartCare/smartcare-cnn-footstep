{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1ee8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e9f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the tag\n",
    "audioset_label = '/m/07pbtc8'\n",
    "cab1 = pd.DataFrame({'YTID':'# YTID, start_seconds, end_seconds, positive_labels'}, index = [0])\n",
    "cab2 = pd.DataFrame({'YTID':'# num_ytids=Dunno, num_segs=Dunno, num_unique_labels=Dunno, num_positive_labels=Dunno'}, index = [0])\n",
    "cab3 = pd.DataFrame({'YTID':'# Segments csv adapted from original eval_segments provided by audioset'}, index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afab1ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTID</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>end_seconds</th>\n",
       "      <th>positive_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># Segments csv adapted from original eval_segm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># num_ytids=Dunno, num_segs=Dunno, num_unique_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># YTID, start_seconds, end_seconds, positive_l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2hQKCE-oTI</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/07pbtc8\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-G_hnfp4a0M</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/04rlf,/m/07pbtc8\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>rjhreFT66-k</td>\n",
       "      <td>120.000</td>\n",
       "      <td>130.000</td>\n",
       "      <td>\"/m/07pbtc8,/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>sggM4ikIIBM</td>\n",
       "      <td>410.000</td>\n",
       "      <td>420.000</td>\n",
       "      <td>\"/m/07pbtc8,/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>uIE6dH5SaNU</td>\n",
       "      <td>160.000</td>\n",
       "      <td>170.000</td>\n",
       "      <td>\"/m/07pbtc8\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>wcby3DVW57s</td>\n",
       "      <td>180.000</td>\n",
       "      <td>190.000</td>\n",
       "      <td>\"/m/05zppz,/m/07pbtc8,/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>zokD5rKQkag</td>\n",
       "      <td>80.000</td>\n",
       "      <td>90.000</td>\n",
       "      <td>\"/m/07pbtc8\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 YTID  ...                  positive_labels\n",
       "0   # Segments csv adapted from original eval_segm...  ...                              NaN\n",
       "1   # num_ytids=Dunno, num_segs=Dunno, num_unique_...  ...                              NaN\n",
       "2   # YTID, start_seconds, end_seconds, positive_l...  ...                              NaN\n",
       "3                                         -2hQKCE-oTI  ...                     \"/m/07pbtc8\"\n",
       "4                                         -G_hnfp4a0M  ...            \"/m/04rlf,/m/07pbtc8\"\n",
       "..                                                ...  ...                              ...\n",
       "58                                        rjhreFT66-k  ...            \"/m/07pbtc8,/m/09x0r\"\n",
       "59                                        sggM4ikIIBM  ...            \"/m/07pbtc8,/m/09x0r\"\n",
       "60                                        uIE6dH5SaNU  ...                     \"/m/07pbtc8\"\n",
       "61                                        wcby3DVW57s  ...  \"/m/05zppz,/m/07pbtc8,/m/09x0r\"\n",
       "62                                        zokD5rKQkag  ...                     \"/m/07pbtc8\"\n",
       "\n",
       "[63 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the train segments CSV\n",
    "balanced_train_df = pd.read_csv(\"data/balanced_train_segments.csv\", sep='\\t', header=None)\n",
    "balanced_train_df.columns = ['label']\n",
    "\n",
    "# Subsetting train segments\n",
    "subset_balanced_train_df = balanced_train_df[balanced_train_df['label'].str.contains(audioset_label, na = False)]\n",
    "\n",
    "split_data = subset_balanced_train_df['label'].str.split(\", \")\n",
    "data = split_data.to_list()\n",
    "names = ['YTID', 'start_seconds', 'end_seconds', 'positive_labels']\n",
    "subset_balanced_train_df = pd.DataFrame(data, columns=names)\n",
    "\n",
    "# simply concatenate both dataframes\n",
    "subset_balanced_train_df = pd.concat([cab1, subset_balanced_train_df]).reset_index(drop = True)\n",
    "subset_balanced_train_df = pd.concat([cab2, subset_balanced_train_df]).reset_index(drop = True)\n",
    "subset_balanced_train_df = pd.concat([cab3, subset_balanced_train_df]).reset_index(drop = True)\n",
    "\n",
    "# This cell converts de DataFrame back into a CSV \n",
    "subset_balanced_train_df.to_csv(r'D:\\Sistemas de Informação\\TCC\\data\\segments\\subset_balanced_train_segments.csv', index = False, header=None)\n",
    "subset_balanced_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01707d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTID</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>end_seconds</th>\n",
       "      <th>positive_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># Segments csv adapted from original eval_segm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># num_ytids=Dunno, num_segs=Dunno, num_unique_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># YTID, start_seconds, end_seconds, positive_l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0CamVQdP_Y</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>\"/m/04rlf,/m/07pbtc8,/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-RKQEJbjXx0</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/07pbtc8\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>v2Ng8iGwf40</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/04rlf,/m/07pbtc8,/m/07qdb04\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>wYREdw4nz4E</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/07pbtc8\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>xQCTXqu3tok</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/07pbtc8,/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>xRI7bHwercI</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/07pbtc8\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>yXeKrbtMz2M</td>\n",
       "      <td>10.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>\"/m/04rlf,/m/05zppz,/m/07pbtc8,/m/09x0r\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 YTID  ...                           positive_labels\n",
       "0   # Segments csv adapted from original eval_segm...  ...                                       NaN\n",
       "1   # num_ytids=Dunno, num_segs=Dunno, num_unique_...  ...                                       NaN\n",
       "2   # YTID, start_seconds, end_seconds, positive_l...  ...                                       NaN\n",
       "3                                         -0CamVQdP_Y  ...            \"/m/04rlf,/m/07pbtc8,/m/09x0r\"\n",
       "4                                         -RKQEJbjXx0  ...                              \"/m/07pbtc8\"\n",
       "..                                                ...  ...                                       ...\n",
       "58                                        v2Ng8iGwf40  ...          \"/m/04rlf,/m/07pbtc8,/m/07qdb04\"\n",
       "59                                        wYREdw4nz4E  ...                              \"/m/07pbtc8\"\n",
       "60                                        xQCTXqu3tok  ...                     \"/m/07pbtc8,/m/09x0r\"\n",
       "61                                        xRI7bHwercI  ...                              \"/m/07pbtc8\"\n",
       "62                                        yXeKrbtMz2M  ...  \"/m/04rlf,/m/05zppz,/m/07pbtc8,/m/09x0r\"\n",
       "\n",
       "[63 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the eval segments CSV\n",
    "eval_df = pd.read_csv(\"data/eval_segments.csv\", sep='\\t', header=None)\n",
    "eval_df.columns = ['label']\n",
    "\n",
    "# Subsetting eval segments\n",
    "subset_eval_df = eval_df[eval_df['label'].str.contains(audioset_label, na = False)]\n",
    "\n",
    "split_data = subset_eval_df['label'].str.split(\", \")\n",
    "data = split_data.to_list()\n",
    "names = ['YTID', 'start_seconds', 'end_seconds', 'positive_labels']\n",
    "subset_eval_df = pd.DataFrame(data, columns=names)\n",
    "\n",
    "# simply concatenate both dataframes\n",
    "subset_eval_df = pd.concat([cab1, subset_eval_df]).reset_index(drop = True)\n",
    "subset_eval_df = pd.concat([cab2, subset_eval_df]).reset_index(drop = True)\n",
    "subset_eval_df = pd.concat([cab3, subset_eval_df]).reset_index(drop = True)\n",
    "\n",
    "# This cell converts de DataFrame back into a CSV \n",
    "subset_eval_df.to_csv(r'D:\\Sistemas de Informação\\TCC\\data\\segments\\subset_eval_segments.csv', index = False, header=None)\n",
    "subset_eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8372cf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTID</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>end_seconds</th>\n",
       "      <th>positive_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># Segments csv adapted from original eval_segm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># num_ytids=Dunno, num_segs=Dunno, num_unique_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># YTID, start_seconds, end_seconds, positive_l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--diQGtdz9Q</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/07pbtc8,/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2ni2KI5S5A</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>\"/m/04rlf,/m/07pbtc8,/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>zimraU2bmGw</td>\n",
       "      <td>150.000</td>\n",
       "      <td>160.000</td>\n",
       "      <td>\"/m/01yg9g,/m/07pbtc8\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>zq8c_jVKhcY</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/07pbtc8\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>zvl4DmtdgdY</td>\n",
       "      <td>50.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>\"/m/07pbtc8,/t/dd00125\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>zvmTtzJkcu0</td>\n",
       "      <td>60.000</td>\n",
       "      <td>70.000</td>\n",
       "      <td>\"/m/07pbtc8,/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>zwyS3CFHd00</td>\n",
       "      <td>140.000</td>\n",
       "      <td>150.000</td>\n",
       "      <td>\"/m/07pbtc8\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1566 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   YTID  ...                 positive_labels\n",
       "0     # Segments csv adapted from original eval_segm...  ...                             NaN\n",
       "1     # num_ytids=Dunno, num_segs=Dunno, num_unique_...  ...                             NaN\n",
       "2     # YTID, start_seconds, end_seconds, positive_l...  ...                             NaN\n",
       "3                                           --diQGtdz9Q  ...           \"/m/07pbtc8,/m/09x0r\"\n",
       "4                                           -2ni2KI5S5A  ...  \"/m/04rlf,/m/07pbtc8,/m/09x0r\"\n",
       "...                                                 ...  ...                             ...\n",
       "1561                                        zimraU2bmGw  ...          \"/m/01yg9g,/m/07pbtc8\"\n",
       "1562                                        zq8c_jVKhcY  ...                    \"/m/07pbtc8\"\n",
       "1563                                        zvl4DmtdgdY  ...         \"/m/07pbtc8,/t/dd00125\"\n",
       "1564                                        zvmTtzJkcu0  ...           \"/m/07pbtc8,/m/09x0r\"\n",
       "1565                                        zwyS3CFHd00  ...                    \"/m/07pbtc8\"\n",
       "\n",
       "[1566 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the unbalanced segments CSV\n",
    "unbalanced_train_df = pd.read_csv(\"data/unbalanced_train_segments.csv\", sep='\\t', header=None)\n",
    "unbalanced_train_df.columns = ['label']\n",
    "\n",
    "# Subsetting unbalanced segments\n",
    "subset_unbalanced_train_df = unbalanced_train_df[unbalanced_train_df['label'].str.contains(audioset_label, na = False)]\n",
    "\n",
    "split_data = subset_unbalanced_train_df['label'].str.split(\", \")\n",
    "data = split_data.to_list()\n",
    "names = ['YTID', 'start_seconds', 'end_seconds', 'positive_labels']\n",
    "subset_unbalanced_train_df = pd.DataFrame(data, columns=names)\n",
    "\n",
    "# simply concatenate both dataframes\n",
    "subset_unbalanced_train_df = pd.concat([cab1, subset_unbalanced_train_df]).reset_index(drop = True)\n",
    "subset_unbalanced_train_df = pd.concat([cab2, subset_unbalanced_train_df]).reset_index(drop = True)\n",
    "subset_unbalanced_train_df = pd.concat([cab3, subset_unbalanced_train_df]).reset_index(drop = True)\n",
    "\n",
    "# This cell converts de DataFrame back into a CSV \n",
    "subset_unbalanced_train_df.to_csv(r'D:\\Sistemas de Informação\\TCC\\data\\segments\\2000max_subset_unbalanced_train_segments.csv', index = False, header=None)\n",
    "subset_unbalanced_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1549b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTID</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>end_seconds</th>\n",
       "      <th>positive_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># Segments csv adapted from original eval_segm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># num_ytids=Dunno, num_segs=Dunno, num_unique_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># YTID, start_seconds, end_seconds, positive_l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--04kMEQOAs</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>\"/m/06h7j,/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--6YSADAJ58</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>\"/m/06h7j,/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>zySuJdkc3TQ</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/03k3r,/m/06h7j,/m/09x0r,/m/0jbk,/t/dd00126\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10406</th>\n",
       "      <td>zyv9LT8EB4A</td>\n",
       "      <td>80.000</td>\n",
       "      <td>90.000</td>\n",
       "      <td>\"/m/0463cq4,/m/04rlf,/m/09x0r,/t/dd00002,/t/dd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10407</th>\n",
       "      <td>zz03MOxL48Y</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>\"/m/0463cq4,/m/09x0r,/m/0ytgt,/t/dd00125\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10408</th>\n",
       "      <td>zzVYJYUPNG8</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/06h7j,/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10409</th>\n",
       "      <td>zzvWbSyZfr0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>\"/m/01d3sd,/m/09x0r\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10410 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    YTID  ...                                    positive_labels\n",
       "0      # Segments csv adapted from original eval_segm...  ...                                                NaN\n",
       "1      # num_ytids=Dunno, num_segs=Dunno, num_unique_...  ...                                                NaN\n",
       "2      # YTID, start_seconds, end_seconds, positive_l...  ...                                                NaN\n",
       "3                                            --04kMEQOAs  ...                                \"/m/06h7j,/m/09x0r\"\n",
       "4                                            --6YSADAJ58  ...                                \"/m/06h7j,/m/09x0r\"\n",
       "...                                                  ...  ...                                                ...\n",
       "10405                                        zySuJdkc3TQ  ...    \"/m/03k3r,/m/06h7j,/m/09x0r,/m/0jbk,/t/dd00126\"\n",
       "10406                                        zyv9LT8EB4A  ...  \"/m/0463cq4,/m/04rlf,/m/09x0r,/t/dd00002,/t/dd...\n",
       "10407                                        zz03MOxL48Y  ...          \"/m/0463cq4,/m/09x0r,/m/0ytgt,/t/dd00125\"\n",
       "10408                                        zzVYJYUPNG8  ...                                \"/m/06h7j,/m/09x0r\"\n",
       "10409                                        zzvWbSyZfr0  ...                               \"/m/01d3sd,/m/09x0r\"\n",
       "\n",
       "[10410 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tags reference Screaming, Crying, Cough, Snoring, Run, Chewing\n",
    "audioset_other_labels = '/m/03qc9zr|/m/0463cq4|/m/01b_21|/m/01d3sd|/m/06h7j|/m/03cczk'\n",
    "\n",
    "# Reading the unbalanced segments CSV\n",
    "unbalanced_train_1600_df = pd.read_csv(\"data/unbalanced_train_segments.csv\", sep='\\t', header=None)\n",
    "unbalanced_train_1600_df.columns = ['label']\n",
    "\n",
    "# Subsetting unbalanced segments\n",
    "subset_unbalanced_train_1600_df = unbalanced_train_1600_df[unbalanced_train_1600_df['label'].str.contains(audioset_other_labels, na = False)]\n",
    "\n",
    "split_data = subset_unbalanced_train_1600_df['label'].str.split(\", \")\n",
    "data = split_data.to_list()\n",
    "names = ['YTID', 'start_seconds', 'end_seconds', 'positive_labels']\n",
    "subset_unbalanced_train_1600_df = pd.DataFrame(data, columns=names)\n",
    "\n",
    "# simply concatenate both dataframes\n",
    "subset_unbalanced_train_1600_df = pd.concat([cab1, subset_unbalanced_train_1600_df]).reset_index(drop = True)\n",
    "subset_unbalanced_train_1600_df = pd.concat([cab2, subset_unbalanced_train_1600_df]).reset_index(drop = True)\n",
    "subset_unbalanced_train_1600_df = pd.concat([cab3, subset_unbalanced_train_1600_df]).reset_index(drop = True)\n",
    "\n",
    "# This cell converts de DataFrame back into a CSV \n",
    "subset_unbalanced_train_1600_df.to_csv(r'D:\\Sistemas de Informação\\TCC\\segments\\max_subset_unbalanced_train_segments.csv', index = False, header=None)\n",
    "subset_unbalanced_train_1600_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41c707f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTID</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>end_seconds</th>\n",
       "      <th>positive_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6339</th>\n",
       "      <td>_BUgLh893Kw</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/04rlf,/m/06h7j\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8491</th>\n",
       "      <td>n_1blRUJebs</td>\n",
       "      <td>60.000</td>\n",
       "      <td>70.000</td>\n",
       "      <td>\"/m/01d3sd\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10083</th>\n",
       "      <td>xrinnBnPDfo</td>\n",
       "      <td>40.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>\"/m/01b_21\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>elPDKalb4Dk</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/04rlf,/m/06h7j,/m/09x0r,/t/dd00128\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>MmRLGPVScxc</td>\n",
       "      <td>280.000</td>\n",
       "      <td>290.000</td>\n",
       "      <td>\"/m/0463cq4,/m/09x0r,/t/dd00125\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3764</th>\n",
       "      <td>K1mN4X98Hkc</td>\n",
       "      <td>110.000</td>\n",
       "      <td>120.000</td>\n",
       "      <td>\"/m/03qc9zr,/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8302</th>\n",
       "      <td>mKf-qrudeIE</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/06h7j,/m/09x0r,/m/0ytgt,/t/dd00128\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-_3_gYXwmw0</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/06h7j,/m/09x0r,/t/dd00129\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>HDMdYNZ0FsI</td>\n",
       "      <td>10.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>\"/m/01d3sd\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1E_jzLpWNKM</td>\n",
       "      <td>110.000</td>\n",
       "      <td>120.000</td>\n",
       "      <td>\"/m/01d3sd\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              YTID  ...                          positive_labels\n",
       "6339   _BUgLh893Kw  ...                      \"/m/04rlf,/m/06h7j\"\n",
       "8491   n_1blRUJebs  ...                              \"/m/01d3sd\"\n",
       "10083  xrinnBnPDfo  ...                              \"/m/01b_21\"\n",
       "7194   elPDKalb4Dk  ...  \"/m/04rlf,/m/06h7j,/m/09x0r,/t/dd00128\"\n",
       "4206   MmRLGPVScxc  ...         \"/m/0463cq4,/m/09x0r,/t/dd00125\"\n",
       "...            ...  ...                                      ...\n",
       "3764   K1mN4X98Hkc  ...                    \"/m/03qc9zr,/m/09x0r\"\n",
       "8302   mKf-qrudeIE  ...  \"/m/06h7j,/m/09x0r,/m/0ytgt,/t/dd00128\"\n",
       "147    -_3_gYXwmw0  ...           \"/m/06h7j,/m/09x0r,/t/dd00129\"\n",
       "3331   HDMdYNZ0FsI  ...                              \"/m/01d3sd\"\n",
       "567    1E_jzLpWNKM  ...                              \"/m/01d3sd\"\n",
       "\n",
       "[1400 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "sample = random.sample(range(4,10419), 1400)\n",
    "train_1600_df = pd.DataFrame(subset_unbalanced_train_1600_df)\n",
    "train_1600_df=train_1600_df.loc[sample]\n",
    "train_1600_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "805e7815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTID</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>end_seconds</th>\n",
       "      <th>positive_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># Segments csv adapted from original eval_segm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># num_ytids=Dunno, num_segs=Dunno, num_unique_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># YTID, start_seconds, end_seconds, positive_l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_BUgLh893Kw</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/04rlf,/m/06h7j\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n_1blRUJebs</td>\n",
       "      <td>60.000</td>\n",
       "      <td>70.000</td>\n",
       "      <td>\"/m/01d3sd\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>K1mN4X98Hkc</td>\n",
       "      <td>110.000</td>\n",
       "      <td>120.000</td>\n",
       "      <td>\"/m/03qc9zr,/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>mKf-qrudeIE</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/06h7j,/m/09x0r,/m/0ytgt,/t/dd00128\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>-_3_gYXwmw0</td>\n",
       "      <td>30.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>\"/m/06h7j,/m/09x0r,/t/dd00129\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>HDMdYNZ0FsI</td>\n",
       "      <td>10.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>\"/m/01d3sd\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>1E_jzLpWNKM</td>\n",
       "      <td>110.000</td>\n",
       "      <td>120.000</td>\n",
       "      <td>\"/m/01d3sd\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1403 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   YTID  ...                          positive_labels\n",
       "0     # Segments csv adapted from original eval_segm...  ...                                      NaN\n",
       "1     # num_ytids=Dunno, num_segs=Dunno, num_unique_...  ...                                      NaN\n",
       "2     # YTID, start_seconds, end_seconds, positive_l...  ...                                      NaN\n",
       "3                                           _BUgLh893Kw  ...                      \"/m/04rlf,/m/06h7j\"\n",
       "4                                           n_1blRUJebs  ...                              \"/m/01d3sd\"\n",
       "...                                                 ...  ...                                      ...\n",
       "1398                                        K1mN4X98Hkc  ...                    \"/m/03qc9zr,/m/09x0r\"\n",
       "1399                                        mKf-qrudeIE  ...  \"/m/06h7j,/m/09x0r,/m/0ytgt,/t/dd00128\"\n",
       "1400                                        -_3_gYXwmw0  ...           \"/m/06h7j,/m/09x0r,/t/dd00129\"\n",
       "1401                                        HDMdYNZ0FsI  ...                              \"/m/01d3sd\"\n",
       "1402                                        1E_jzLpWNKM  ...                              \"/m/01d3sd\"\n",
       "\n",
       "[1403 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simply concatenate both dataframes\n",
    "train_1600_df = pd.concat([cab1, train_1600_df]).reset_index(drop = True)\n",
    "train_1600_df = pd.concat([cab2, train_1600_df]).reset_index(drop = True)\n",
    "train_1600_df = pd.concat([cab3, train_1600_df]).reset_index(drop = True)\n",
    "\n",
    "# This cell converts de DataFrame back into a CSV \n",
    "train_1600_df.to_csv(r'D:\\Sistemas de Informação\\TCC\\segments\\1600max_subset_unbalanced_train_segments.csv', index = False, header=None)\n",
    "train_1600_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
